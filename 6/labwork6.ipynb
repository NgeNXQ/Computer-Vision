{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторна робота № 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ІП-14 Бабіч Денис"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Розробити програмний скрипт, що реалізує стеження за об’єктом у цифровому відеопотоці. Зміст відео, об’єкт стеження – обрати самостійно. Метод та технологію стеження обрати такою, що забезпечує стійкість процесу object-tracking для обраних вихідними даними (відео, об’єкт стеження). Вибір обґрунтувати та довести його ефективність."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Підготовчий етап"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Імпортування необхідних модулів"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Основний етап"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Застосування на прикладі знаходження рис обличчя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY_ESCAPE = 27\n",
    "\n",
    "CLASSIFIER_EYE = cv2.CascadeClassifier(f\"{cv2.data.haarcascades}haarcascade_eye.xml\")\n",
    "CLASSIFIER_SMILE = cv2.CascadeClassifier(f\"{cv2.data.haarcascades}haarcascade_smile.xml\")\n",
    "CLASSIFIER_FACE = cv2.CascadeClassifier(f\"{cv2.data.haarcascades}haarcascade_frontalface_default.xml\")\n",
    "\n",
    "BOUNDING_THICKNESS = 2\n",
    "COLOR_EYE = (255, 0, 0)\n",
    "COLOR_FACE = (0, 255, 0)\n",
    "COLOR_SMILE = (0, 0, 255)\n",
    "\n",
    "CAPTURE = cv2.VideoCapture(\"video1.mp4\")\n",
    "FPS = int(CAPTURE.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "while True:\n",
    "    ret, frame = CAPTURE.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray_filter = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = CLASSIFIER_FACE.detectMultiScale(gray_filter, scaleFactor = 1.05, minNeighbors = 5)\n",
    "\n",
    "    for (x, y, width, height) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x + width, y + height), COLOR_FACE, BOUNDING_THICKNESS)\n",
    "\n",
    "        roi_color = frame[y:(y + height), x:(x + width)]\n",
    "        roi_gray = gray_filter[y:(y + height), x:(x + width)]\n",
    "\n",
    "        eyes = CLASSIFIER_EYE.detectMultiScale(roi_gray, scaleFactor = 1.1, minNeighbors = 5)\n",
    "\n",
    "        for (x, y, width, height) in eyes:\n",
    "            cv2.rectangle(roi_color, (x, y), (x + width, y + height), COLOR_EYE, BOUNDING_THICKNESS)\n",
    "\n",
    "        smiles = CLASSIFIER_SMILE.detectMultiScale(roi_gray, scaleFactor = 1.2, minNeighbors = 125)\n",
    "\n",
    "        for (x, y, width, height) in smiles:\n",
    "            cv2.rectangle(roi_color, (x, y), (x + width, y + height), COLOR_SMILE, BOUNDING_THICKNESS)\n",
    "\n",
    "    cv2.imshow(\"Detected face features\", frame)\n",
    "\n",
    "    if cv2.waitKey(FPS) & 0xFF == KEY_ESCAPE:\n",
    "        break\n",
    "\n",
    "CAPTURE.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Застосування на прикладі знаходження людей на відео"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY_ESCAPE = 27\n",
    "\n",
    "HOG_DESCRIPTOR = cv2.HOGDescriptor()\n",
    "HOG_DESCRIPTOR.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "BOUNDING_THICKNESS = 2\n",
    "COLOR_HUMAN = (0, 255, 255)\n",
    "\n",
    "CAPTURE = cv2.VideoCapture(\"video2.mp4\")\n",
    "FPS = int(CAPTURE.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "while True:\n",
    "    _, frame = CAPTURE.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray_filter = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    people = HOG_DESCRIPTOR.detectMultiScale(gray_filter, winStride = (8, 8), padding = (16, 16), scale = 1.25)\n",
    "    people = np.array([[human_x, human_y, human_x + human_w, human_y + human_h] for (human_x, human_y, human_w, human_h) in people[0]])\n",
    "\n",
    "    for (x, y, width, height) in people:\n",
    "        cv2.rectangle(frame, (x, y), (width, height), COLOR_HUMAN, BOUNDING_THICKNESS)\n",
    "\n",
    "    cv2.imshow(\"Detected individuals\", frame)\n",
    "\n",
    "    if cv2.waitKey(FPS) & 0xFF == KEY_ESCAPE:\n",
    "        break\n",
    "\n",
    "CAPTURE.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
